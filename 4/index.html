<!DOCTYPE html>
<html lang="en">
<head>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CS180 • Project 2 — Part 1</title>
  <link rel="stylesheet" href="style.css" />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
  <header class="page-header">
    <h1>CS180 — Project 2</h1>
    <p class="author-name">Eason Wei</p>
  </header>

  <main class="container">

    <!-- ===================== Part 1 ===================== -->
      <h2 class="section-title">Part 1</h2>

      <!-- =========== Part 1.1 =========== -->
      <article id="part1-1">
        <h3 class="section-title">1.1 Convolutions from Scratch</h3>

        <!-- Results Row -->
        <h4 class="section-title">Results (Grayscale Selfie &amp; Derivatives)</h4>

        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_1/selfie_gray.png" />
            <figcaption>Original (Grayscale)</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_1/selfie_box_scipy.png" alt="Selfie after convolution (box filter)" />
            <figcaption>After Convolution (Box Filter)</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_1/selfie_Ix.png" alt="Selfie Lx" />
            <figcaption>Finite Difference: L<sub>x</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_1/selfie_Iy.png" alt="Selfie Ly" />
            <figcaption>Finite Difference: L<sub>y</sub></figcaption>
          </figure>
        </div>

        <p class="explainer-text">
          The four nested for-loop implementation of convolution is extremely slow. 
          Efficiency improves significantly when switching to the two for-loop version, 
          where I pad the image with zeros using <code>np.pad</code> based on the kernel size. 
          My self-implemented convolution functions produce the exact same output as the built-in 
          <code>scipy.signal.convolve2d</code>. Compared to the original grayscale selfie, the box-filtered 
          result appears blurred. Additionally, convolving the image with D<sub>x</sub> and D<sub>y</sub> 
          produces the corresponding derivative images shown above.
        </p>

        <details class="code-toggle">
          <summary>Show / Hide my convolution code</summary>

          <div class="code-columns">
            <figure class="code-card">
              <figcaption class="code-title">Four-Loop Convolution (no padding)</figcaption>
<pre class="code-block"><code>def conv2d_four_forloops(img, kernel, pad_value: float = 0.0):
    H, W = img.shape
    kh, kw = kernel.shape
    ch, cw = kh // 2, kw // 2
    k   = _flip_kernel(kernel).astype(np.float32, copy=False)
    img = img.astype(np.float32, copy=False)
    out = np.zeros((H, W), dtype=np.float32)

    for i in range(H):
        for j in range(W):
            s = 0.0
            for u in range(-ch, ch + 1):
                for v in range(-cw, cw + 1):
                    ii = i + u
                    jj = j + v
                    ku = ch + u
                    kv = cw + v
                    if 0 &lt;= ii &lt; H and 0 &lt;= jj &lt; W:
                        s += img[ii, jj] * k[ku, kv]
            out[i, j] = s
    return out</code></pre>
            </figure>

            <figure class="code-card">
              <figcaption class="code-title">Two-Loop Convolution (zero padding)</figcaption>
<pre class="code-block"><code>def conv2d_two_forloops(img, kernel, pad_value: float = 0.0):
    H, W = img.shape
    kh, kw = kernel.shape
    k = _flip_kernel(kernel)
    ch, cw = kh // 2, kw // 2
    out = np.zeros((H, W), dtype=np.float32)
    padded = np.pad(img, ((ch, ch), (cw, cw)), mode='constant', constant_values=pad_value)
    for i in range(H):
        for j in range(W):
            window = padded[i:i+kh, j:j+kw]
            out[i, j] = np.sum(window * k, dtype=np.float32)
    return out</code></pre>
            </figure>
          </div>
        </details>
      </article>

      <!-- =========== Part 1.2 =========== -->
      <article id="part1-2">
        <h3 class="section-title">1.2 Edge Detection with Finite Differences</h3>

        <!-- Results Row -->
        <h4 class="section-title">Results (Edge Maps &amp; Gradient)</h4>

        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_2/Ix.png" alt="Lx Gradient" />
            <figcaption>Gradient L<sub>x</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_2/Iy.png" alt="Ly Gradient" />
            <figcaption>Gradient L<sub>y</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_2/gradient.png" alt="Gradient Magnitude" />
            <figcaption>Gradient Magnitude</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_2/binarize_edges.png" alt="Binarized Edges" />
            <figcaption>Binarized Edge Map</figcaption>
          </figure>
        </div>

        <p class="explainer-text">
          Using the finite difference operators D<sub>x</sub> and D<sub>y</sub>, I computed the partial
          derivatives of the image in both the horizontal and vertical directions. Combining these
          results gives the gradient magnitude map, which highlights edges regardless of orientation.
          By applying a threshold of 0.32~0.34 the gradient magnitude is converted into a binarized edge map, which successfully eliminating most of the background noise
          while outlining the major boundaries in the image.
        </p>
      </article>

      <!-- =========== Part 1.3 =========== -->
      <article id="part1-3">
        <h3 class="section-title">1.3 Derivative of Gaussian (DoG) Filter</h3>

        <!-- Results Row -->
        <h4 class="section-title">Results (Gaussian Smoothing &amp; DoG)</h4>

        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_3/edges_blur.png" alt="Gaussian Blur edge map" />
            <figcaption>Gaussian Blur edge map</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_3/edges_DoG.png" alt="DoG Gaussian edge map" />
            <figcaption>DoG Gaussian edge map<sub>x</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_3/gradient_blur.png" alt="Gaussian Blur gradient" />
            <figcaption>Gaussian Blur gradient<sub>y</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_3/gradient_DoG.png" alt="DoG Gaussian Blur gradient" />
            <figcaption>DoG Gaussian Blur gradient</figcaption>
          </figure>
        </div>

        <p class="explainer-text">
          Applying finite difference operators directly on the original image (as in Part 1.2) often produces noisy edge maps.
          By first smoothing the image with a Gaussian filter (as in Part 1.3), noise is reduced and edges appear sharper and more coherent. 
          The Derivative of Gaussian (DoG) filters combine smoothing and differentiation into a single operation, producing results equivalent to 
          applying Gaussian blur followed by convolution with D<sub>x</sub> or D<sub>y</sub>.
          
          Interestingly, while both approaches yield visually identical binarized edge maps at a threshold of 0.2, their gradient magnitudes differ 
          slightly. The DoG results appear somewhat brighter compared to the Gaussian-blur-then-differentiate approach. This discrepancy is likely due to 
          subtle differences in numerical precision and the order of operations: in the DoG method, the derivative is embedded in the Gaussian kernel itself, 
          whereas in the two-step method, smoothing and differentiation are performed sequentially
        </p>
      </article>

<!-- =========== Part 2.1 =========== -->
<article id="part2-1">
  <h3 class="section-title">2.1 Image Sharpening</h3>

  <!-- Top Row -->
  <h4 class="section-title">Taj Mahal Example</h4>
  <div class="image-strip" role="list">
    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/taj_demo/0_original.png" alt="Original Taj" />
      <figcaption>Original</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/taj_demo/1_blurred.png" alt="Blurred Taj" />
      <figcaption>Blurred</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/taj_demo/2_highfreq_vis.png" alt="High-Freq Taj" />
      <figcaption>High-Frequency</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/taj_demo/3_sharp_two_step.png" alt="Sharpened Taj" />
      <figcaption>Sharpened</figcaption>
    </figure>
  </div>

  <p class="explainer-text">
  In this part, I first applied a Gaussian blur to the original Taj image. 
  Subtracting the blurred result from the original yields the high-frequency component. 
  This high-frequency detail is then scaled by a factor <em>α</em> and added back to the original image. 
  The parameter <em>α</em> controls how much detail is reintroduced: higher values produce a crisper 
  but potentially noisier result. The sharpened Taj image demonstrates enhanced edges and fine details.
</p>

<div class="equation-box">
  <p><strong>Sharpening Formula:</strong></p>
  <p>
    $$ I_{\text{sharp}} \;=\; I \;+\; \alpha \left( I - (G_{\sigma} * I) \right) $$
  </p>
</div>
  <!-- Bottom Row -->
  <h4 class="section-title">Pyramid Example</h4>
  <div class="image-strip" role="list">
    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/pyramid/0_original.png" alt="Original Pyramid" />
      <figcaption>Original</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/pyramid/5_demo_blurred.png" alt="Blurred Pyramid" />
      <figcaption>Blurred</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/pyramid/2_highfreq_vis.png" alt="High-Freq Pyramid" />
      <figcaption>High-Frequency</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/pyramid/6_demo_resharpened.png" alt="Resharpened Pyramid" />
      <figcaption>Resharpened</figcaption>
    </figure>
  </div>

  <p class="explainer-text">
    In the pyramid example, the resharpened image cannot be fully restored to its original quality because the high-frequency 
    details were already lost during the initial Gaussian blur. When applying the unsharp mask, we blur the image again to compute the 
    high-frequency component. However, since this is done on an already blurred image, many fine details are irretrievably lost. 
    As a result, the resharpening process only adds back a limited portion of the high-frequency content, making the 
    final image appear sharper than the blurred version but still noticeably less detailed compared to the original.
  </p>
</article>
      <!-- =========== Part 2.2 =========== -->
      <article id="part2-2">
        <h3 class="section-title">2.2 Hybrid Images</h3>

        <h4 class="section-title">Hybrid Example 1: Full Process</h4>

        <!-- Originals -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_orig_high.png" alt="Original High Source" />
            <figcaption>Dog (High-Frequency Source)</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_orig_low.png" alt="Original Low Source" />
            <figcaption>Cat (Low-Frequency Source)</figcaption>
          </figure>
        </div>

        <!-- FFT of Originals -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_orig_high.png" alt="FFT Original High" />
            <figcaption>Original FFT Dog</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_orig_low.png" alt="FFT Original Low" />
            <figcaption>Original FFT Cat</figcaption>
          </figure>
        </div>

        <!-- Filtered -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_highpass_vis.png" alt="High-Pass Filtered" />
            <figcaption>High-Pass Dog</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_lowpass.png" alt="Low-Pass Filtered" />
            <figcaption>Low-Pass Cat</figcaption>
          </figure>
        </div>

        <!-- FFTs -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_lowpass.png" alt="FFT Low-Pass" />
            <figcaption>FFT of Low-Pass</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_highpass.png" alt="FFT High-Pass" />
            <figcaption>FFT of High-Pass</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_hybrid.png" alt="FFT Hybrid" />
            <figcaption>FFT of Hybrid</figcaption>
          </figure>
        </div>

        <!-- Final Hybrid -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_hybrid.png" alt="Hybrid Final" />
            <figcaption>Final Hybrid (Dog + Cat)</figcaption>
            <p class="cutoff-note">Cutoff Frequencies — Low-pass: σ = 7.0, High-pass: σ = 2.5</p>
          </figure>
        </div>

        <!-- Equation -->
        <div class="equation-box">
          <p>The hybrid image is computed as:</p>
          <p>
            \[
            H(x,y) \;=\; \beta \, L(I_\text{low})(x,y) \;+\; \alpha \, H(I_\text{high})(x,y)
            \]
          </p>
        </div>

        <h4 class="section-title">Hybrid Example 2 & 3: Final Results</h4>

        <!-- Hybrid Example 2 -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/nutmeg_Derek/nutmeg_Derek_orig_high.png" alt="Original 3" />
            <figcaption>Nutmeg</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/nutmeg_Derek/nutmeg_Derek_orig_low.png" alt="Original 4" />
            <figcaption>Derek</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/nutmeg_Derek/nutmeg_Derek_hybrid.png" alt="Hybrid 2" />
            <figcaption>Nutmeg-Derek Hybrid Result</figcaption>
            <p class="cutoff-note">Low-pass: σ = 1, High-pass: σ = 2</p>
          </figure>
        </div>

        <!-- Hybrid Example 3 -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/batman_joker/batman_joker_orig_low.png" alt="Original 5" />
            <figcaption>Joker</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/batman_joker/batman_joker_orig_high.png" alt="Original 6" />
            <figcaption>Batman</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/batman_joker/batman_joker_hybrid.png" alt="Hybrid 3" />
            <figcaption>Batman-Joker Hybrid Result</figcaption>
            <p class="cutoff-note">Low-pass: σ = 1.0, High-pass: σ = 8.0</p>
          </figure>
        </div>

      </article>
      <!-- =========== Part 2.3 & 2.4 =========== -->
<article id="part2-3-4">
  <h3 class="section-title">2.3 &amp; 2.4 Multiresolution Blending</h3>

  <h4 class="section-title">Results (Gaussian/Laplacian Stacks and Custom Blends)</h4>


    <!-- Supporting Images Row -->
    <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/data/apple.jpeg" alt="Apple Original"/>
            <figcaption>Apple</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/data/orange.jpeg" alt="Selfie after convolution (box filter)" />
            <figcaption>Orange</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_3/blend_soft.png" alt="Selfie Lx" />
            <figcaption>Orapple</figcaption>
          </figure>
    </div>
    <!-- Big Result -->
    <figure>
      <img class="big-result" src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_3/panel_soft_seam.png" alt="Apple + Orange Stacks" />
      <figcaption>Gaussian &amp; Laplacian Stacks Orapple</figcaption>
    </figure>



    <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/data/hand.jpg" alt="Apple Original"/>
            <figcaption>Hand</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/data/eye.jpg" alt="Selfie after convolution (box filter)" />
            <figcaption>Eye</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_4/hand_eye/blend.png" alt="Selfie Lx" />
            <figcaption>Eye in Hand</figcaption>
          </figure>
    </div>
    <!-- Big Result -->
    <figure>
      <img class="big-result" src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_4/hand_eye/panel.png" alt="Apple + Orange Stacks" />
      <figcaption>Eye in the Hand(Ellipse Mask -- Irregular)</figcaption>
    </figure>
  </div>
  <section id="ellipse-explanation">
  <h3 class="section-title">Explanation of Ellipse Mask and Pyramid Blending</h3>

  <p class="explainer-text">
    The <strong>ellipse mask</strong> is defined on the base image domain \((x, y)\).
    Let the ellipse be centered at \((c_x, c_y)\) with radii \((r_x, r_y)\). 
    A binary mask is first constructed as:
  </p>

  <div class="equation-box">
    \[
    M_{\text{hard}}(x, y) =
      \begin{cases}
        1, & \frac{(x-c_x)^2}{r_x^2} + \frac{(y-c_y)^2}{r_y^2} \leq 1, \\
        0, & \text{otherwise}.
      \end{cases}
    \]
  </div>

  <p class="explainer-text">
    This creates a sharp boundary. To avoid seams, we apply a <strong>Gaussian blur</strong> 
    with standard deviation \(\sigma\) (chosen as a fraction of the image size) 
    to obtain a smooth transition:
  </p>

  <div class="equation-box">
    \[
    M(x, y) = G_\sigma * M_{\text{hard}}(x, y),
    \]
  </div>

  <p class="explainer-text">
    where \(G_\sigma\) is a normalized Gaussian kernel and \(*\) denotes convolution.  
    The resulting \(M(x, y)\) is a soft mask taking values in \([0,1]\), 
    where 1 selects the inserted image and 0 selects the base image.
  </p>

  <p class="explainer-text">
    For blending, the final Laplacian pyramid at each level is constructed as:
  </p>

  <div class="equation-box">
    \[
    L_{\text{blend}}^{(i)} = (1 - M^{(i)}) \cdot L_A^{(i)} + M^{(i)} \cdot L_B^{(i)},
    \]
  </div>

  <p class="explainer-text">
    where \(L_A^{(i)}, L_B^{(i)}\) are Laplacian levels of the base and inserted image, 
    and \(M^{(i)}\) is the Gaussian pyramid of the mask.  
    Summing all \(L_{\text{blend}}^{(i)}\) reconstructs the blended image.
  </p>
</section>



    <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/data/ocean.jpg" alt="Apple Original"/>
            <figcaption>Ocean</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/data/sunset.jpg" alt="Selfie after convolution (box filter)" />
            <figcaption>Sunset</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_4/sunset_ocean/blend.png" alt="Selfie Lx" />
            <figcaption>Sunset on Ocean</figcaption>
          </figure>
    </div>
    <!-- Big Result -->
    <figure>
      <img class="big-result" src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_4/sunset_ocean/panel.png" alt="Apple + Orange Stacks" />
      <figcaption>Sunset on Ocean(Horizontal Mask)</figcaption>
    </figure>
  </div>

</article>
    </section>
  </main>

  <footer class="footer">
    <p>© 2025 • CS180/280A • Project 2 • Eason Wei</p>
  </footer>
</body>
</html>
