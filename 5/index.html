<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<meta name="viewport" content="width=device-width, initial-scale=1.0" />
<title>Project 4: NeRF — Part 0</title>
<link rel="stylesheet" href="style.css" />
</head>

<body>

<header>
  <h1>Project 4: Neural Radiance Fields (NeRF)</h1>
  <h2>Eason Wei — CS180 / Fall 2025</h2>
</header>

<!-- ===== Introduction ===== -->
<section id="intro" class="card">
  <h2>Introduction</h2>
  <p>
    In this project, I implement a full pipeline for reconstructing a 3D scene using 
    <b>Neural Radiance Fields (NeRF)</b>. I begin by <b>calibrating my camera</b> with ArUco markers 
    to recover intrinsics and camera poses. Then, I train a <b>2D neural field</b> to understand how 
    positional encoding and MLPs represent continuous signals. Finally, I build and train a complete 
    <b>3D NeRF</b>, generating rays, sampling points, performing volume rendering, and producing 
    novel-view images and GIFs of the reconstructed object.
  </p>
</section>

<!-- ===== Part 0 ===== -->
<section id="part0">
  <h2>Part 0 — Camera Calibration & 3D Object Scanning</h2>

  <!-- ===== 0.1 Camera Calibration ===== -->
  <h3>0.1 Camera Calibration</h3>
  <p>
    In this section, I printed a 6-tag ArUco grid and captured 50 images of it. Since the originals were 
    in <code>.heic</code> format and very large, I converted them to <code>.jpg</code> using a Python script. 
    I measured each printed tag to be 0.57 units wide and used this measurement to define the 3D coordinates 
    of all tag corners. Using <code>cv2.aruco.detectMarkers</code>, I extracted the 2D corner locations and 
    applied a mask to correctly index all six tags. Finally, I computed the intrinsic matrix <b>K</b> and 
    distortion coefficients using <code>cv2.calibrateCamera</code>.
  </p>

  <!-- ===== 0.2 Object Capture ===== -->
  <h3>0.2 Object Capture</h3>
  <p>
    I captured another 50 images of my chosen object, Labubu, using the same camera settings as calibration. 
    Below are four example images from the dataset.
  </p>

  <div class="img-container" style="display:flex; gap:15px; justify-content:center;">
      <img src="placeholder1.png" alt="Object Example 1" style="width:22%; border-radius:8px;" />
      <img src="placeholder2.png" alt="Object Example 2" style="width:22%; border-radius:8px;" />
      <img src="placeholder3.png" alt="Object Example 3" style="width:22%; border-radius:8px;" />
      <img src="placeholder4.png" alt="Object Example 4" style="width:22%; border-radius:8px;" />
  </div>

  <!-- ===== 0.3 Pose Estimation ===== -->
  <h3>0.3 Pose Estimation (PnP)</h3>
  <p>Insert Viser camera frustum plots here.</p>
  <div class="img-container">
    <img src="images/viser_cam_plot1.png" alt="Viser Camera Plot 1" />
    <img src="images/viser_cam_plot2.png" alt="Viser Camera Plot 2" />
  </div>

  <!-- ===== 0.4 Dataset Packaging ===== -->
  <h3>0.4 Dataset Packaging</h3>
  <p>Insert explanation + final dataset statistics.</p>

</section>

</body>
</html>
