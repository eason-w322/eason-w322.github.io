<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8"/>
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>CS180 Project 5 — Diffusion Models</title>
  <link rel="stylesheet" href="style.css"/>
  <!-- MathJax -->
<script>
  window.MathJax = {
    tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
    svg: { fontCache: 'global' }
  };
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>

<body>

<!-- ===== HEADER ===== -->
<header class="site-header">
  <h1>CS180 Project 5: Diffusion Models</h1>
  <p class="subtitle">Eason Wei | CS 180 — Fall 2025</p>
</header>

<!-- ===== SIDEBAR ===== -->
<nav class="sidebar">
  <ul>
    <li><a href="#part0">Part A — Question 0</a></li>
    
  </ul>
</nav>

<!-- ===== MAIN CONTENT ===== -->
<main class="container">

  <section id="part0" class="card">
    <h2>Part 0: Setup</h2>

    <h3>Text Prompts Used for Prompt Embeddings</h3>

    <p>
      To explore the behavior of the DeepFloyd diffusion model, I generated prompt embeddings
      for a diverse set of text prompts ranging from highly detailed, imaginative scenes to
      very simple object-level descriptions.
    </p>

    <div class="textbox">
      <ul>
        <li>a giant library floating in the clouds, glowing with jellyfish lights</li>
        <li>a neon samurai standing in a rainy cyberpunk street</li>
        <li>a realistic cat dressed like a king in a Renaissance painting</li>
        <li>a crystal dragon coming out of a frozen waterfall at sunrise</li>
        <li>an astronaut walking inside a huge ancient temple on an alien planet</li>
        <li>a tiny house floating inside a glowing glass bubble</li>
        <li>a giant whale swimming through a sky full of clouds</li>
        <li>a robot painting a sunset on a canvas</li>
        <li>a tree growing on top of a small island floating in space</li>
        <li>a traditional Chinese ink painting of mountains, water, and a small boat</li>
        <li>a cartoon owl sitting on a branch</li>
        <li>a small lantern glowing in the night</li>
        <li>a realistic portrait of a human face</li>
        <li>a small cottage on a hill at sunset</li>
        <li>a high quality photo</li>
        <li>a rocket ship</li>
        <li>a Quinjet</li>
        <li>a pyramid</li>
        <li>an oil painting of an old man</li>
        <li>an oil painting of people around a campfire</li>
        <li>a cat</li>
        <li>a dog</li>
        <li>a landscape of a mountain range</li>
        <li>a skull</li>
        <li>a waterfall</li>
      </ul>
    </div>

    <div class="image-stack">
  <figure>
    <img src="part0_50.png" alt="Complex prompt generations">
    <figcaption>
      Results with <b>50 inference steps</b> (seed = <b>180</b>). Some semantic details are
      underdeveloped or missing due to insufficient denoising.
    </figcaption>
  </figure>
</div>

<div class="image-stack">
  <figure>
    <img src="part0_100.png" alt="Simple prompt generations">
    <figcaption>
      Results with <b>100 inference steps</b> (seed = <b>180</b>). Textures and edges are
      noticeably sharper, and previously missing semantic elements—such as the astronaut
      figure—are clearly formed.
    </figcaption>
  </figure>
</div>

  </section>

 <section id="part1_1" class="card">
  <h2>1.1 — Forward Diffusion Process</h2>

  <p>
    The forward diffusion process gradually corrupts a clean image by adding Gaussian noise.
    Given a clean image \(x_0\), the noisy image \(x_t\) at timestep \(t\) is generated by
    scaling the original signal and injecting noise according to a predefined noise schedule.
  </p>

  <p>
    Let \(\bar{\alpha}_t\) denote the cumulative noise coefficient at timestep \(t\).
    The forward process is defined as:
  </p>

  <p class="math-block">
    \[
      x_t = \sqrt{\bar{\alpha}_t}\,x_0 + \sqrt{1 - \bar{\alpha}_t}\,\varepsilon,
      \quad \varepsilon \sim \mathcal{N}(0, I)
    \]
  </p>

  <p>
    Below is the implementation of the forward diffusion function. The noise coefficient
    \(\bar{\alpha}_t\) is retrieved from <code>alphas_cumprod</code>, and the noise
    \(\varepsilon\) is sampled from a standard Gaussian distribution.
  </p>

  <pre><code class="language-python">
def forward(im, t):
    alpha_bar_t = alphas_cumprod[t].to(im.device).type_as(im)
    eps = torch.randn_like(im)
    im_noisy = torch.sqrt(alpha_bar_t) * im + torch.sqrt(1 - alpha_bar_t) * eps
    return im_noisy
  </code></pre>

  <p>
    As \(t\) increases, \(\bar{\alpha}_t\) decreases, causing the original image content
    to fade while noise dominates. At large timesteps, the image approaches pure Gaussian noise.
  </p>

  <!-- ========================= -->
  <!-- Forward Diffusion Results -->
  <!-- ========================= -->
  <div class="image-stack">
    <figure>
      <img src="1.1.png" alt="Forward diffusion at different timesteps">
      <figcaption>
        Forward diffusion applied to the Campanile image at increasing timesteps,
        showing progressively stronger noise as \(t\) grows.
      </figcaption>
    </figure>
  </div>
</section>

</main>

<!-- ===== FOOTER ===== -->
<footer>
  <p>© 2025 Eason Wei | UC Berkeley CS180</p>
</footer>

</body>
</html>
