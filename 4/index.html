<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>CS180 • Project 2 — Part 1</title>
  <link rel="stylesheet" href="style.css" />
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
</head>
<body>
  <header class="page-header">
    <h1>CS180 — Project 2</h1>
    <h2>Part 1: Fun with Filters</h2>
  </header>

  <main class="container">

    <!-- ===================== Part 1 ===================== -->
    <section id="part1">
      <h2 class="section-title">Part 1</h2>

      <!-- =========== Part 1.1 =========== -->
      <article id="part1-1">
        <h3 class="section-title">1.1 Convolutions from Scratch</h3>

        <!-- Results Row -->
        <h4 class="section-title">Results (Grayscale Selfie &amp; Derivatives)</h4>

        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_1/selfie_gray.png" />
            <figcaption>Original (Grayscale)</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_1/selfie_box_scipy.png" alt="Selfie after convolution (box filter)" />
            <figcaption>After Convolution (Box Filter)</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_1/selfie_Ix.png" alt="Selfie Lx" />
            <figcaption>Finite Difference: L<sub>x</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_1/selfie_Iy.png" alt="Selfie Ly" />
            <figcaption>Finite Difference: L<sub>y</sub></figcaption>
          </figure>
        </div>

        <p class="explainer-text">
          The four nested for-loop implementation of convolution is extremely slow. 
          Efficiency improves significantly when switching to the two for-loop version, 
          where I pad the image with zeros using <code>np.pad</code> based on the kernel size. 
          My self-implemented convolution functions produce the exact same output as the built-in 
          <code>scipy.signal.convolve2d</code>. Compared to the original grayscale selfie, the box-filtered 
          result appears blurred. Additionally, convolving the image with D<sub>x</sub> and D<sub>y</sub> 
          produces the corresponding derivative images shown above.
        </p>

        <details class="code-toggle">
          <summary>Show / Hide my convolution code</summary>

          <div class="code-columns">
            <figure class="code-card">
              <figcaption class="code-title">Four-Loop Convolution (no padding)</figcaption>
<pre class="code-block"><code>def conv2d_four_forloops(img, kernel, pad_value: float = 0.0):
    H, W = img.shape
    kh, kw = kernel.shape
    ch, cw = kh // 2, kw // 2
    k   = _flip_kernel(kernel).astype(np.float32, copy=False)
    img = img.astype(np.float32, copy=False)
    out = np.zeros((H, W), dtype=np.float32)

    for i in range(H):
        for j in range(W):
            s = 0.0
            for u in range(-ch, ch + 1):
                for v in range(-cw, cw + 1):
                    ii = i + u
                    jj = j + v
                    ku = ch + u
                    kv = cw + v
                    if 0 &lt;= ii &lt; H and 0 &lt;= jj &lt; W:
                        s += img[ii, jj] * k[ku, kv]
            out[i, j] = s
    return out</code></pre>
            </figure>

            <figure class="code-card">
              <figcaption class="code-title">Two-Loop Convolution (zero padding)</figcaption>
<pre class="code-block"><code>def conv2d_two_forloops(img, kernel, pad_value: float = 0.0):
    H, W = img.shape
    kh, kw = kernel.shape
    k = _flip_kernel(kernel)
    ch, cw = kh // 2, kw // 2
    out = np.zeros((H, W), dtype=np.float32)
    padded = np.pad(img, ((ch, ch), (cw, cw)), mode='constant', constant_values=pad_value)
    for i in range(H):
        for j in range(W):
            window = padded[i:i+kh, j:j+kw]
            out[i, j] = np.sum(window * k, dtype=np.float32)
    return out</code></pre>
            </figure>
          </div>
        </details>
      </article>

      <!-- =========== Part 1.2 =========== -->
      <article id="part1-2">
        <h3 class="section-title">1.2 Edge Detection with Finite Differences</h3>

        <!-- Results Row -->
        <h4 class="section-title">Results (Edge Maps &amp; Gradient)</h4>

        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_2/Ix.png" alt="Lx Gradient" />
            <figcaption>Gradient L<sub>x</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_2/Iy.png" alt="Ly Gradient" />
            <figcaption>Gradient L<sub>y</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_2/gradient.png" alt="Gradient Magnitude" />
            <figcaption>Gradient Magnitude</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_2/binarize_edges.png" alt="Binarized Edges" />
            <figcaption>Binarized Edge Map</figcaption>
          </figure>
        </div>

        <p class="explainer-text">
          Using the finite difference operators D<sub>x</sub> and D<sub>y</sub>, I computed the partial
          derivatives of the image in both the horizontal and vertical directions. Combining these
          results gives the gradient magnitude map, which highlights edges regardless of orientation.
          By applying a threshold of 0.32~0.34 the gradient magnitude is converted into a binarized edge map, which successfully eliminating most of the background noise
          while outlining the major boundaries in the image.
        </p>
      </article>

      <!-- =========== Part 1.3 =========== -->
      <article id="part1-3">
        <h3 class="section-title">1.3 Derivative of Gaussian (DoG) Filter</h3>

        <!-- Results Row -->
        <h4 class="section-title">Results (Gaussian Smoothing &amp; DoG)</h4>

        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_3/edges_blur.png" alt="Gaussian Blur edge map" />
            <figcaption>Gaussian Blur edge map</figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_3/edges_DoG.png" alt="DoG Gaussian edge map" />
            <figcaption>DoG Gaussian edge map<sub>x</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_3/gradient_blur.png" alt="Gaussian Blur gradient" />
            <figcaption>Gaussian Blur gradient<sub>y</sub></figcaption>
          </figure>

          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part1_3/gradient_DoG.png" alt="DoG Gaussian Blur gradient" />
            <figcaption>DoG Gaussian Blur gradient</figcaption>
          </figure>
        </div>

        <p class="explainer-text">
          Applying finite difference operators directly on the original image (as in Part 1.2) often produces noisy edge maps.
          By first smoothing the image with a Gaussian filter (as in Part 1.3), noise is reduced and edges appear sharper and more coherent. 
          The Derivative of Gaussian (DoG) filters combine smoothing and differentiation into a single operation, producing results equivalent to 
          applying Gaussian blur followed by convolution with D<sub>x</sub> or D<sub>y</sub>.
          
          Interestingly, while both approaches yield visually identical binarized edge maps at a threshold of 0.2, their gradient magnitudes differ 
          slightly. The DoG results appear somewhat brighter compared to the Gaussian-blur-then-differentiate approach. This discrepancy is likely due to 
          subtle differences in numerical precision and the order of operations: in the DoG method, the derivative is embedded in the Gaussian kernel itself, 
          whereas in the two-step method, smoothing and differentiation are performed sequentially
        </p>
      </article>

<!-- =========== Part 2.1 =========== -->
<article id="part2-1">
  <h3 class="section-title">2.1 Image Sharpening</h3>

  <!-- Top Row -->
  <h4 class="section-title">Taj Mahal Example</h4>
  <div class="image-strip" role="list">
    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/taj_demo/0_original.png" alt="Original Taj" />
      <figcaption>Original</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/taj_demo/1_blurred.png" alt="Blurred Taj" />
      <figcaption>Blurred</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/taj_demo/2_highfreq_vis.png" alt="High-Freq Taj" />
      <figcaption>High-Frequency</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/taj_demo/3_sharp_two_step.png" alt="Sharpened Taj" />
      <figcaption>Sharpened</figcaption>
    </figure>
  </div>

  <p class="explainer-text">
  In this part, I first applied a Gaussian blur to the original Taj image. 
  Subtracting the blurred result from the original yields the high-frequency component. 
  This high-frequency detail is then scaled by a factor <em>α</em> and added back to the original image. 
  The parameter <em>α</em> controls how much detail is reintroduced: higher values produce a crisper 
  but potentially noisier result. The sharpened Taj image demonstrates enhanced edges and fine details.
</p>

<div class="equation-box">
  <p><strong>Sharpening Formula:</strong></p>
  <p>
    $$ I_{\text{sharp}} \;=\; I \;+\; \alpha \left( I - (G_{\sigma} * I) \right) $$
  </p>
</div>
  <!-- Bottom Row -->
  <h4 class="section-title">Pyramid Example</h4>
  <div class="image-strip" role="list">
    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/pyramid/0_original.png" alt="Original Pyramid" />
      <figcaption>Original</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/pyramid/5_demo_blurred.png" alt="Blurred Pyramid" />
      <figcaption>Blurred</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/pyramid/2_highfreq_vis.png" alt="High-Freq Pyramid" />
      <figcaption>High-Frequency</figcaption>
    </figure>

    <figure role="listitem">
      <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_1/pyramid/6_demo_resharpened.png" alt="Resharpened Pyramid" />
      <figcaption>Resharpened</figcaption>
    </figure>
  </div>

  <p class="explainer-text">
    In the pyramid example, the resharpened image cannot be fully restored to its original quality because the high-frequency 
    details were already lost during the initial Gaussian blur. When applying the unsharp mask, we blur the image again to compute the 
    high-frequency component. However, since this is done on an already blurred image, many fine details are irretrievably lost. 
    As a result, the resharpening process only adds back a limited portion of the high-frequency content, making the 
    final image appear sharper than the blurred version but still noticeably less detailed compared to the original.
  </p>
</article>
      <!-- =========== Part 2.2 =========== -->
      <article id="part2-2">
        <h3 class="section-title">2.2 Hybrid Images</h3>

        <h4 class="section-title">Hybrid Example 1: Full Process</h4>

        <!-- Originals -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_orig_high.png" alt="Original High Source" />
            <figcaption>Dog (High-Frequency Source)</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_orig_low.png" alt="Original Low Source" />
            <figcaption>Cat (Low-Frequency Source)</figcaption>
          </figure>
        </div>

        <!-- FFT of Originals -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_orig_high.png" alt="FFT Original High" />
            <figcaption>Original FFT Dog</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_orig_low.png" alt="FFT Original Low" />
            <figcaption>Original FFT Cat</figcaption>
          </figure>
        </div>

        <!-- Filtered -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_highpass_vis.png" alt="High-Pass Filtered" />
            <figcaption>High-Pass Dog</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_lowpass.png" alt="Low-Pass Filtered" />
            <figcaption>Low-Pass Cat</figcaption>
          </figure>
        </div>

        <!-- FFTs -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_lowpass.png" alt="FFT Low-Pass" />
            <figcaption>FFT of Low-Pass</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_highpass.png" alt="FFT High-Pass" />
            <figcaption>FFT of High-Pass</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_fft_hybrid.png" alt="FFT Hybrid" />
            <figcaption>FFT of Hybrid</figcaption>
          </figure>
        </div>

        <!-- Final Hybrid -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/dog_cat/dog_cat_hybrid.png" alt="Hybrid Final" />
            <figcaption>Final Hybrid (Dog + Cat)</figcaption>
            <p class="cutoff-note">Cutoff Frequencies — Low-pass: σ = 7.0, High-pass: σ = 2.5</p>
          </figure>
        </div>

        <!-- Equation -->
        <div class="equation-box">
          <p>The hybrid image is computed as:</p>
          <p>
            \[
            H(x,y) \;=\; \beta \, L(I_\text{low})(x,y) \;+\; \alpha \, H(I_\text{high})(x,y)
            \]
          </p>
        </div>

        <h4 class="section-title">Hybrid Example 2 & 3: Final Results</h4>

        <!-- Hybrid Example 2 -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/nutmeg_Derek/nutmeg_Derek_orig_high.png" alt="Original 3" />
            <figcaption>Nutmeg</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/nutmeg_Derek/nutmeg_Derek_orig_low.png" alt="Original 4" />
            <figcaption>Derek</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/nutmeg_Derek/nutmeg_Derek_hybrid.png" alt="Hybrid 2" />
            <figcaption>Nutmeg-Derek Hybrid Result</figcaption>
            <p class="cutoff-note">Low-pass: σ = 1, High-pass: σ = 2</p>
          </figure>
        </div>

        <!-- Hybrid Example 3 -->
        <div class="image-strip" role="list">
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/batman_joker/batman_joker_orig_low.png" alt="Original 5" />
            <figcaption>Joker</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/batman_joker/batman_joker_orig_high.png" alt="Original 6" />
            <figcaption>Batman</figcaption>
          </figure>
          <figure role="listitem">
            <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_2/batman_joker/batman_joker_hybrid.png" alt="Hybrid 3" />
            <figcaption>Batman-Joker Hybrid Result</figcaption>
            <p class="cutoff-note">Low-pass: σ = 1.0, High-pass: σ = 8.0</p>
          </figure>
        </div>

      </article>
      <!-- =========== Part 2.3 & 2.4 =========== -->
<article id="part2-3-4">
  <h3 class="section-title">2.3 &amp; 2.4 Multiresolution Blending</h3>

  <h4 class="section-title">Results (Gaussian/Laplacian Stacks and Custom Blends)</h4>

  <div class="blend-group">
    <!-- Supporting Images Row -->
    <div class="support-strip">
      <figure>
        <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/data/apple.jpeg" alt="Apple Original" />
        <figcaption>Apple</figcaption>
      </figure>
      <figure>
        <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/data/orange.jpeg" alt="Orange Original" />
        <figcaption>Orange</figcaption>
      </figure>
      <figure>
        <img src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_3/blend_soft.png" alt="Mask" />
        <figcaption>Orapple</figcaption>
      </figure>
    </div>
    <!-- Big Result -->
    <figure>
      <img class="big-result" src="https://raw.githubusercontent.com/eason-w322/CS180-Project-2/main/results/part2_3/blend_soft_seam.png" alt="Apple + Orange Stacks" />
      <figcaption>Gaussian &amp; Laplacian Stacks Orapple</figcaption>
    </figure>
  </div>

  <div class="blend-group">
    <div class="support-strip">
      <figure>
        <img src="REPLACE_URL/custom1_a.png" alt="Original A" />
        <figcaption>Original A</figcaption>
      </figure>
      <figure>
        <img src="REPLACE_URL/custom1_b.png" alt="Original B" />
        <figcaption>Original B</figcaption>
      </figure>
      <figure>
        <img src="REPLACE_URL/custom1_mask.png" alt="Straight Mask" />
        <figcaption>Straight Mask</figcaption>
      </figure>
    </div>
    <figure>
      <img class="big-result" src="REPLACE_URL/custom1_blend.png" alt="Custom Blend 1" />
      <figcaption>Custom Blend 1 — Straight Mask</figcaption>
    </figure>
  </div>

  <div class="blend-group">
    <div class="support-strip">
      <figure>
        <img src="REPLACE_URL/custom2_a.png" alt="Original C" />
        <figcaption>Original C</figcaption>
      </figure>
      <figure>
        <img src="REPLACE_URL/custom2_b.png" alt="Original D" />
        <figcaption>Original D</figcaption>
      </figure>
      <figure>
        <img src="REPLACE_URL/custom2_mask.png" alt="Irregular Mask" />
        <figcaption>Irregular Mask</figcaption>
      </figure>
    </div>
    <figure>
      <img class="big-result" src="REPLACE_URL/custom2_blend.png" alt="Custom Blend 2" />
      <figcaption>Custom Blend 2 — Irregular Mask</figcaption>
    </figure>
  </div>

  <p class="explainer-text">
    For Part 2.3, I implemented Gaussian and Laplacian stacks to visualize the multiresolution
    decomposition of the Apple and Orange images. This reproduces the outcomes of Figure 3.42 (a–l),
    where Gaussian levels progressively blur the images and Laplacian levels highlight band-pass details.
    <br><br>
    In Part 2.4, I used these stacks for blending. The Apple and Orange blend demonstrates seamless
    multiresolution blending. Additionally, I created two custom blends: one with a straight mask
    and another with an irregular mask. The irregular mask demonstrates the advantage of multiresolution
    blending by producing smooth transitions without visible seams.
  </p>
</article>
    </section>
  </main>

  <footer class="footer">
    <p>© 2025 • CS180/280A • Project 2</p>
  </footer>
</body>
</html>
