<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>CS180 Project 3: Image Warping and Mosaicing</title>
  <link rel="stylesheet" href="style.css">
</head>

<body>
  <!-- ===== HEADER ===== -->
  <header class="site-header">
    <h1>Project 3: Image Warping and Mosaicing</h1>
    <p class="subtitle">Eason Wei | CS 180 / 280A – Fall 2025</p>
  </header>

  <!-- ===== SIDEBAR NAVIGATION ===== -->
  <nav class="sidebar">
    <ul>
      <li><a href="#partA1">A.1 – Shoot and Digitize Pictures</a></li>
      <li><a href="#partA2">A.2 – Recover Homographies</a></li>
      <li><a href="#partA3">A.3 – Warp the Images</a></li>
      <li><a href="#partA4">A.4 – Blend into a Mosaic</a></li>
    </ul>
  </nav>

  <!-- ===== MAIN CONTENT ===== -->
  <main class="container">

    <!-- ===== Overview Section ===== -->
    <section id="intro" class="card">
      <h2>Overview</h2>
      <p>
        In this project, I explore <b>image warping</b> and <b>mosaicing</b> to create seamless panoramas
        from multiple photographs. The goal is to recover homographies between images, warp them using
        nearest-neighbor and bilinear interpolation, and blend them into smooth mosaics.
      </p>
    </section>

    <!-- ===== Part A.1 Section ===== -->
    <section id="partA1" class="card">
      <h2>A.1 – Shoot and Digitize Pictures</h2>
      <p>
        I captured multiple photo sets by rotating the camera about a fixed center of projection
        to create projective transformations suitable for mosaicing. Each image overlaps the next
        by a portion to ensure reliable feature matching and homography estimation.
      </p>

      <div class="image-stack">
        <figure>
          <img src="set1_projective_images.png" alt="Set 1 - Piano With Projective Transformation">
          <figcaption>Set 1 - Piano With Projective Transformation</figcaption>
        </figure>

        <figure>
          <img src="set2_projective_images.png" alt="Set 2 - View with Projective Transformation">
          <figcaption>Set 2 - View with Projective Transformation</figcaption>
        </figure>

        <figure>
          <img src="images/set1_img3.jpg" alt="Set 1 - Image 3">
          <figcaption>Image 3</figcaption>
        </figure>
      </div>
    </section>

    <!-- Placeholders for next parts -->
    <section id="partA2" class="card"><h2>A.2 – Recover Homographies</h2>
      <p>
    Before warping the images into alignment, I first need to recover the parameters of the 
    <b>projective transformation</b> (homography) that maps points from one image to another. 
    The goal is to find a 3×3 matrix <b>H</b> such that \( p' = H p \), where \(p = [x, y, 1]^T\) 
    and \(p' = [u, v, 1]^T\).
  </p>

  <h3>1. Homography Definition</h3>
  <p>
    Since the last entry can be fixed to 1, the matrix has eight unknowns:
  </p>
  <p class="math-block">
    \[
    H =
    \begin{bmatrix}
    h_1 & h_2 & h_3 \\
    h_4 & h_5 & h_6 \\
    h_7 & h_8 & 1
    \end{bmatrix}
    \]
  </p>

  <p>
    Expanding the homogeneous relation \(p' = H p\) yields:
  </p>

  <p class="math-block">
    \[
    \begin{cases}
    u = \frac{h_1 x + h_2 y + h_3}{h_7 x + h_8 y + 1}, \\[6pt]
    v = \frac{h_4 x + h_5 y + h_6}{h_7 x + h_8 y + 1}.
    \end{cases}
    \]
  </p>

  <p>
    Multiplying through by the denominators gives two linear equations per correspondence:
  </p>

  <p class="math-block">
    \[
    \begin{cases}
    x h_1 + y h_2 + h_3 - u x h_7 - u y h_8 = u,\\[6pt]
    x h_4 + y h_5 + h_6 - v x h_7 - v y h_8 = v.
    \end{cases}
    \]
  </p>

  <h3>2. Constructing the Linear System</h3>
  <p>
    Each correspondence contributes two rows to a matrix <b>A</b> and a right-hand side vector <b>b</b>:
  </p>

  <p class="math-block">
    \[
    A_i =
    \begin{bmatrix}
    x_i & y_i & 1 & 0 & 0 & 0 & -u_i x_i & -u_i y_i\\
    0 & 0 & 0 & x_i & y_i & 1 & -v_i x_i & -v_i y_i
    \end{bmatrix},\quad
    b_i =
    \begin{bmatrix}
    u_i \\ v_i
    \end{bmatrix}
    \]
  </p>

  <p>
    Stacking all n point correspondences, we form the full system:
  </p>

  <p class="math-block">
    \[
    A\,h = b,\quad
    A \in \mathbb{R}^{2n \times 8},\;
    h = [h_1,h_2,h_3,h_4,h_5,h_6,h_7,h_8]^T.
    \]
  </p>

  <p>
    For four points, the system can be solved exactly, but for stability and robustness, 
    I use <b>more than four correspondences</b> and solve the overdetermined system using 
    the least-squares solution:
  </p>

  <p class="math-block">
    \[
    h = (A^T A)^{-1} A^T b.
    \]
  </p>

  <p>
    Finally, the solution vector \(h\) is reshaped into the 3×3 matrix \(H\) by appending the bottom row \([0,0,1]\):
  </p>

  <p class="math-block">
    \[
    H =
    \begin{bmatrix}
    h_1 & h_2 & h_3\\
    h_4 & h_5 & h_6\\
    h_7 & h_8 & 1
    \end{bmatrix}.
    \]
  </p>

  <h3>3. Visualizing Point Correspondences</h3>
  <p>
    To verify the quality of the selected correspondences, I plotted both images side by side and 
    connected matching feature points using <b>red lines</b>. I manually chose 
    <b>eight pairs</b> of distinctive features such as piano corners, window edges, and structural intersections. 
    The visualization clearly demonstrates consistent geometry between the two images, confirming that the 
    computed homography accurately models the perspective transformation.
  </p>

  <figure style="text-align: center; margin: 20px 0;">
    <img src="piano1_to_piano2_correspondences_ls.png" alt="piano1 to piano2 correspondences" style="max-width: 90%; border-radius: 10px; border: 1px solid var(--border); box-shadow: 0 0 10px rgba(0,0,0,0.4);">
    <figcaption style="color: var(--muted); margin-top: 8px;">
      piano1 → piano2 Correspondences 
    </figcaption>
  </figure>

  <h3>4. Recovered Homography Matrix</h3>
  <p>
    The estimated homography matrix \(H\) for the piano1 → piano2 transformation is:
  </p>

  <p class="math-block">
    \[
    H =
    \begin{bmatrix}
    1.9173 & 0.0029 & -1088.9868 \\[4pt]
    0.3469 & 1.5827 & -380.8842 \\[4pt]
    0.0005 & -0.000005 & 1.0000
    \end{bmatrix}
    \]
  </p>
</section>

<!-- MathJax for LaTeX equations -->
<script>
window.MathJax = {
  tex: {inlineMath: [['$', '$'], ['\\(', '\\)']]},
  svg: {fontCache: 'global'}
};
</script>
<script id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
</script>
    </section>
    <section id="partA3" class="card"><h2>A.3 – Warp the Images</h2>
      <p>
    With the homography matrix \(H\) recovered, the next step is to <b>warp each image</b> toward
    the reference frame. The process maps every pixel in the target image to its corresponding
    location in the source image through <b>inverse warping</b>, ensuring no holes appear in the result.
  </p>

  <!-- ========================= -->
  <!-- A.3.1 Image Warping -->
  <!-- ========================= -->
  <h3>A.3.1 – Image Warping</h3>
  <p>
    I implemented two warping functions from scratch:
    <code>warpImageNearestNeighbor(im, H)</code> and
    <code>warpImageBilinear(im, H)</code>.
    Both use inverse warping but differ in how they estimate pixel values:
  </p>

  <ul>
    <li><b>Nearest Neighbor:</b> rounds mapped coordinates to the closest integer pixel.</li>
    <li><b>Bilinear:</b> computes a weighted average of the four surrounding pixels
        (interpolating along x first, then y).</li>
  </ul>

  <p>Below are representative excerpts illustrating their key difference:</p>

  <pre><code class="language-python"># Nearest Neighbor
x_nn, y_nn = int(round(x)), int(round(y))
if 0 &lt;= x_nn &lt; w and 0 &lt;= y_nn &lt; h:
    warped[y_out, x_out] = im[y_nn, x_nn]
  </code></pre>

  <pre><code class="language-python"># Bilinear Interpolation
x0, y0 = int(np.floor(x)), int(np.floor(y))
dx, dy = x - x0, y - y0
I_top = (1-dx)*im[y0, x0] + dx*im[y0, x0+1]
I_bottom = (1-dx)*im[y0+1, x0] + dx*im[y0+1, x0+1]
warped[y_out, x_out] = (1-dy)*I_top + dy*I_bottom
  </code></pre>

  <figure style="text-align:center; margin:24px 0;">
    <img src="piano_middle_to_piano_right.png"
         alt="Warp result Nearest Neighbor vs Bilinear"
         style="max-width:90%; border-radius:10px; border:1px solid var(--border);
                box-shadow:0 0 10px rgba(0,0,0,0.4);">
    <figcaption style="color:var(--muted); margin-top:8px;">
      Comparison of Nearest Neighbor (12.26 s) vs Bilinear (24.61 s)
    </figcaption>
  </figure>

  <p>
    The Nearest Neighbor method runs roughly twice as fast but produces
    visibly jagged edges and aliasing artifacts. Bilinear interpolation
    smooths the image substantially at the cost of computation time.
    This trade-off between <b>speed</b> and <b>visual quality</b>
    becomes more pronounced at high resolutions.
  </p>

  <!-- ========================= -->
  <!-- A.3.2 Rectification -->
  <!-- ========================= -->
  <h3>A.3.2 – Image Rectification</h3>
  <p>
    To verify the correctness of my warping pipeline, I performed
    <b>rectification</b> — mapping an oblique planar surface back to a
    fronto-parallel rectangle. For each test, I manually clicked four
    corner points of a slanted rectangular object in the image
    (<code>im1_pts</code>) and mapped them to a perfect square
    (<code>im2_pts = [[0,0],[0,1],[1,0],[1,1]]</code>).
  </p>

  <p>
    Applying the computed homography warps the perspective so that
    the object appears rectangular again, confirming the accuracy of
    the inverse warping and interpolation logic.
  </p>

  <figure style="text-align:center; margin:20px 0;">
    <img src="rectification_before.png"
         alt="Rectification before"
         style="max-width:85%; border-radius:10px; border:1px solid var(--border);
                box-shadow:0 0 10px rgba(0,0,0,0.4); margin-bottom:10px;">
    <img src="rectification_after.png"
         alt="Rectification after"
         style="max-width:85%; border-radius:10px; border:1px solid var(--border);
                box-shadow:0 0 10px rgba(0,0,0,0.4);">
    <figcaption style="color:var(--muted); margin-top:8px;">
      Rectification results – slanted rectangles restored to a frontal view.
    </figcaption>
  </figure>

  <div class="notes">
    These rectification tests verify that the warping functions correctly
    model projective transformations. Bilinear interpolation yields
    smoother, more photorealistic results, while Nearest Neighbor offers
    a quicker but less refined approximation.
  </div>
</section>
    
    
    
    </section>
    <section id="partA4" class="card"><h2>A.4 – Blend into a Mosaic</h2></section>
  </main>

  <!-- ===== FOOTER ===== -->
  <footer>
    <p>© 2025 Eason Wei | UC Berkeley CS180 – Image Mosaicing</p>
  </footer>
</body>
</html>
